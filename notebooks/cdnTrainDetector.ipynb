{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score,auc, roc_curve\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../anomalydetection/code\")\n",
    "\n",
    "from anomalyDetector_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(window_size):\n",
    "    \n",
    "    aCDN = np.load(\"../data/data.npy\")\n",
    "    anomalyInformation = np.load(\"../data/condInput.npy\")\n",
    "    \n",
    "    x,y,labels = apply_sliding_window(aCDN, anomalyInformation, window_size=window_size)\n",
    "    \n",
    "    return x,y,labels\n",
    "\n",
    "def apply_sliding_window(X,aMetaInformation,window_size):\n",
    "    \n",
    "    \n",
    "    return_x = np.zeros(shape=[X.shape[0]-window_size,window_size,X.shape[1]])\n",
    "    return_y = np.zeros(shape=[X.shape[0]-window_size,X.shape[1]])\n",
    "    return_label = np.zeros(shape=[X.shape[0]-window_size,1])\n",
    "    \n",
    "    for i in range(0, int(X.shape[0]-window_size)):\n",
    "        return_x[i] = X[i:i+window_size]\n",
    "        return_y[i] = X[i+window_size]\n",
    "        return_label[i] = aMetaInformation[i+window_size]\n",
    "        \n",
    "    return return_x.reshape(-1,window_size,X.shape[1]), return_y.reshape(-1,X.shape[1]), return_label.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_config = {\n",
    "    \"window_size\": 64,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 500,\n",
    "    \"train_size\": 0.9,\n",
    "    \"val_size\": 0.05,\n",
    "    \"test_size\": 0.05,\n",
    "    \"patience\": 150,\n",
    "    \"modified_loss\": \"minmax\",\n",
    "    \"multivariates\": 3\n",
    "    \n",
    "}\n",
    "\n",
    "tcn_model_config = {\n",
    "    \"architecture\": \"TCN\",\n",
    "    \"channels\": 20,\n",
    "    \"num_layers\": 2,\n",
    "    \"kernel_size\": 5,\n",
    "    \"dropout\": 0.5,\n",
    "}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,labels = load_data(training_data_config[\"window_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "tcnAnomalyDetector = AnomalyDetector(training_data_config,tcn_model_config,(x,y,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./  already exists\n",
      "Validation loss decreased (inf --> 0.825453).  Saving model ...\n",
      "Epoch 0: Train-Loss: 0.004255750682204962, Val-Loss: 0.002901822328567505, Val-AUC: 0.8254531557108539\n",
      "Validation loss decreased (0.825453 --> 0.841286).  Saving model ...\n",
      "Epoch 1: Train-Loss: 0.001793196890503168, Val-Loss: 0.002912066411226988, Val-AUC: 0.8412863070539419\n",
      "Validation loss decreased (0.841286 --> 0.858812).  Saving model ...\n",
      "Epoch 2: Train-Loss: 0.001692664809525013, Val-Loss: 0.002880442887544632, Val-AUC: 0.8588119676785324\n",
      "Epoch 3: Train-Loss: 0.0015770846512168646, Val-Loss: 0.0027762537356466055, Val-AUC: 0.8316226250272984\n",
      "Validation loss decreased (0.858812 --> 0.881306).  Saving model ...\n",
      "Epoch 4: Train-Loss: 0.001513012102805078, Val-Loss: 0.002841054927557707, Val-AUC: 0.8813059620004368\n",
      "Epoch 5: Train-Loss: 0.0014755388256162405, Val-Loss: 0.0026532402262091637, Val-AUC: 0.8478925529591614\n",
      "Epoch 6: Train-Loss: 0.0014110113261267543, Val-Loss: 0.0025663529522717, Val-AUC: 0.8608866564752129\n",
      "Epoch 7: Train-Loss: 0.0013762109447270632, Val-Loss: 0.0025479826144874096, Val-AUC: 0.87065953264905\n",
      "Epoch 8: Train-Loss: 0.0013368335785344243, Val-Loss: 0.0025573873426765203, Val-AUC: 0.863125136492684\n",
      "Epoch 9: Train-Loss: 0.0013010844122618437, Val-Loss: 0.002473030239343643, Val-AUC: 0.8633981218606683\n",
      "Validation loss decreased (0.881306 --> 0.882835).  Saving model ...\n",
      "Epoch 10: Train-Loss: 0.0013141653034836054, Val-Loss: 0.0024666041135787964, Val-AUC: 0.8828346800611486\n",
      "Epoch 11: Train-Loss: 0.0012617823667824268, Val-Loss: 0.0024257423356175423, Val-AUC: 0.8747543131688141\n",
      "Epoch 12: Train-Loss: 0.0012552073458209634, Val-Loss: 0.0024809495080262423, Val-AUC: 0.835990390915047\n",
      "Epoch 13: Train-Loss: 0.0012425421737134457, Val-Loss: 0.002479770453646779, Val-AUC: 0.8405765450971827\n",
      "Epoch 14: Train-Loss: 0.001279020099900663, Val-Loss: 0.0023683777544647455, Val-AUC: 0.8594671325616947\n",
      "Epoch 15: Train-Loss: 0.0012410356430336833, Val-Loss: 0.0023145023733377457, Val-AUC: 0.8486569119895173\n",
      "Epoch 16: Train-Loss: 0.0012398588005453348, Val-Loss: 0.002383389975875616, Val-AUC: 0.8648722428477833\n",
      "Epoch 17: Train-Loss: 0.0012425943277776241, Val-Loss: 0.0023730851244181395, Val-AUC: 0.8791220790565625\n",
      "Epoch 18: Train-Loss: 0.0012168674729764462, Val-Loss: 0.0024240834172815084, Val-AUC: 0.8664555579820922\n",
      "Epoch 19: Train-Loss: 0.0012176074087619781, Val-Loss: 0.002324123168364167, Val-AUC: 0.8701681589866783\n",
      "Epoch 20: Train-Loss: 0.001228871988132596, Val-Loss: 0.0023430148139595985, Val-AUC: 0.8646538545533959\n",
      "Epoch 21: Train-Loss: 0.001223365543410182, Val-Loss: 0.0022631343454122543, Val-AUC: 0.8628521511246997\n",
      "Epoch 22: Train-Loss: 0.001233867253176868, Val-Loss: 0.0023167787585407495, Val-AUC: 0.8601768945184538\n",
      "Epoch 23: Train-Loss: 0.0012081149034202099, Val-Loss: 0.0022825554478913546, Val-AUC: 0.8820157239571957\n",
      "Epoch 24: Train-Loss: 0.0011818697676062584, Val-Loss: 0.002286588540300727, Val-AUC: 0.8370277353133873\n",
      "Epoch 25: Train-Loss: 0.0011600834550336003, Val-Loss: 0.002298967679962516, Val-AUC: 0.8743721336536362\n",
      "Epoch 26: Train-Loss: 0.001182541367597878, Val-Loss: 0.002326278481632471, Val-AUC: 0.8786307053941909\n",
      "Validation loss decreased (0.882835 --> 0.884527).  Saving model ...\n",
      "Epoch 27: Train-Loss: 0.0011648801155388355, Val-Loss: 0.002293385099619627, Val-AUC: 0.8845271893426512\n",
      "Epoch 28: Train-Loss: 0.001202593557536602, Val-Loss: 0.0022010314278304577, Val-AUC: 0.8302576981873772\n",
      "Epoch 29: Train-Loss: 0.001185525907203555, Val-Loss: 0.0022721358109265566, Val-AUC: 0.8835990390915047\n",
      "Epoch 30: Train-Loss: 0.0011688907397910953, Val-Loss: 0.0023092941846698523, Val-AUC: 0.8531884690980563\n",
      "Epoch 31: Train-Loss: 0.0011851665331050754, Val-Loss: 0.0022587657440453768, Val-AUC: 0.8712055033850187\n",
      "Epoch 32: Train-Loss: 0.001174292410723865, Val-Loss: 0.0022126571275293827, Val-AUC: 0.8330967460144136\n",
      "Epoch 33: Train-Loss: 0.001154210651293397, Val-Loss: 0.002452284563332796, Val-AUC: 0.8783577200262067\n",
      "Epoch 34: Train-Loss: 0.0011739842593669891, Val-Loss: 0.0022955727763473988, Val-AUC: 0.7622297444856956\n",
      "Epoch 35: Train-Loss: 0.001173240365460515, Val-Loss: 0.0023266184143722057, Val-AUC: 0.871806071194584\n",
      "Epoch 36: Train-Loss: 0.0011754113947972655, Val-Loss: 0.0022959306370466948, Val-AUC: 0.8539528281284123\n",
      "Epoch 37: Train-Loss: 0.001146488357335329, Val-Loss: 0.0023030706215649843, Val-AUC: 0.8782485258790129\n",
      "Epoch 38: Train-Loss: 0.0011579114943742752, Val-Loss: 0.002275598468258977, Val-AUC: 0.8680934701899978\n",
      "Epoch 39: Train-Loss: 0.0011249673552811146, Val-Loss: 0.0023336338344961405, Val-AUC: 0.8637257043022494\n",
      "Epoch 40: Train-Loss: 0.001176332705654204, Val-Loss: 0.0021788093727082014, Val-AUC: 0.8537890369076218\n",
      "Epoch 41: Train-Loss: 0.0011402368545532227, Val-Loss: 0.0022117902990430593, Val-AUC: 0.8587027735313387\n",
      "Epoch 42: Train-Loss: 0.0011786924442276359, Val-Loss: 0.002341978484764695, Val-AUC: 0.8724612360777463\n",
      "Epoch 43: Train-Loss: 0.001172923482954502, Val-Loss: 0.0022769763600081205, Val-AUC: 0.8611050447696003\n",
      "Epoch 44: Train-Loss: 0.001151616801507771, Val-Loss: 0.0022419607266783714, Val-AUC: 0.8436339812186067\n",
      "Epoch 45: Train-Loss: 0.0011779963970184326, Val-Loss: 0.002279947279021144, Val-AUC: 0.8556453374099147\n",
      "Epoch 46: Train-Loss: 0.00117901258636266, Val-Loss: 0.0022571159061044455, Val-AUC: 0.8638894955230398\n",
      "Epoch 47: Train-Loss: 0.0011506940936669707, Val-Loss: 0.002183732343837619, Val-AUC: 0.86006770037126\n",
      "Epoch 48: Train-Loss: 0.0011333967559039593, Val-Loss: 0.0022208925802260637, Val-AUC: 0.8724066390041494\n",
      "Epoch 49: Train-Loss: 0.0012114878045395017, Val-Loss: 0.002296933438628912, Val-AUC: 0.8805416029700808\n",
      "Epoch 50: Train-Loss: 0.0011802722001448274, Val-Loss: 0.0022126019466668367, Val-AUC: 0.86197859794715\n",
      "Epoch 51: Train-Loss: 0.0011178896529600024, Val-Loss: 0.0022934218868613243, Val-AUC: 0.841996069010701\n",
      "Epoch 52: Train-Loss: 0.001130846212618053, Val-Loss: 0.0022990191355347633, Val-AUC: 0.8737169687704739\n",
      "Epoch 53: Train-Loss: 0.0010833709966391325, Val-Loss: 0.002456367714330554, Val-AUC: 0.8802140205284997\n",
      "Epoch 54: Train-Loss: 0.001166199566796422, Val-Loss: 0.002227289602160454, Val-AUC: 0.8655820048045425\n",
      "Epoch 55: Train-Loss: 0.0011589311761781573, Val-Loss: 0.0022105907555669546, Val-AUC: 0.8737715658440707\n",
      "Epoch 56: Train-Loss: 0.001164752640761435, Val-Loss: 0.0021322749089449644, Val-AUC: 0.8563005022930771\n",
      "Epoch 57: Train-Loss: 0.0011391332373023033, Val-Loss: 0.002232462167739868, Val-AUC: 0.8516597510373445\n",
      "Epoch 58: Train-Loss: 0.0011442770482972264, Val-Loss: 0.002259101253002882, Val-AUC: 0.8834352478707141\n",
      "Epoch 59: Train-Loss: 0.0011561538558453321, Val-Loss: 0.0022035615984350443, Val-AUC: 0.8707687267962436\n",
      "Epoch 60: Train-Loss: 0.0011565865715965629, Val-Loss: 0.002175556030124426, Val-AUC: 0.8810875737060494\n",
      "Epoch 61: Train-Loss: 0.0011505541624501348, Val-Loss: 0.002214622450992465, Val-AUC: 0.8690216204411443\n",
      "Epoch 62: Train-Loss: 0.0011197623098269105, Val-Loss: 0.0021844443399459124, Val-AUC: 0.8761192400087354\n",
      "Epoch 63: Train-Loss: 0.001113983104005456, Val-Loss: 0.002265443094074726, Val-AUC: 0.8601768945184538\n",
      "Epoch 64: Train-Loss: 0.001119254739023745, Val-Loss: 0.002145986072719097, Val-AUC: 0.8179187595544879\n",
      "Epoch 65: Train-Loss: 0.0011567516485229135, Val-Loss: 0.00219622696749866, Val-AUC: 0.8589211618257261\n",
      "Epoch 66: Train-Loss: 0.0011364968959242105, Val-Loss: 0.0021515730768442154, Val-AUC: 0.847674164664774\n",
      "Epoch 67: Train-Loss: 0.0011177149135619402, Val-Loss: 0.0022772219963371754, Val-AUC: 0.8611596418431973\n",
      "Validation loss decreased (0.884527 --> 0.885401).  Saving model ...\n",
      "Epoch 68: Train-Loss: 0.0011163899907842278, Val-Loss: 0.0023726318031549454, Val-AUC: 0.8854007425202008\n",
      "Epoch 69: Train-Loss: 0.0011463129194453359, Val-Loss: 0.0021521442104130983, Val-AUC: 0.876283031229526\n",
      "Epoch 70: Train-Loss: 0.0010954048484563828, Val-Loss: 0.002255992265418172, Val-AUC: 0.8765560165975104\n",
      "Epoch 71: Train-Loss: 0.0010976108023896813, Val-Loss: 0.0020679570734500885, Val-AUC: 0.8603952828128412\n",
      "Epoch 72: Train-Loss: 0.0011431322200223804, Val-Loss: 0.002149381907656789, Val-AUC: 0.8621423891679407\n",
      "Epoch 73: Train-Loss: 0.0011265815701335669, Val-Loss: 0.0021024623420089483, Val-AUC: 0.8764468224503166\n",
      "Epoch 74: Train-Loss: 0.0011314598377794027, Val-Loss: 0.0021377659868448973, Val-AUC: 0.868421052631579\n",
      "Epoch 75: Train-Loss: 0.0011112340725958347, Val-Loss: 0.0022955001331865788, Val-AUC: 0.884636383489845\n",
      "Epoch 76: Train-Loss: 0.0011479327222332358, Val-Loss: 0.002232327125966549, Val-AUC: 0.7519654946494868\n",
      "Epoch 77: Train-Loss: 0.0011451812461018562, Val-Loss: 0.0021487362682819366, Val-AUC: 0.8779209434374319\n",
      "Epoch 78: Train-Loss: 0.0011292011477053165, Val-Loss: 0.0023135922383517027, Val-AUC: 0.8796134527189343\n",
      "Epoch 79: Train-Loss: 0.0011069760657846928, Val-Loss: 0.00223425030708313, Val-AUC: 0.8537890369076218\n",
      "Epoch 80: Train-Loss: 0.0011212299577891827, Val-Loss: 0.002183944685384631, Val-AUC: 0.8696767853243066\n",
      "Validation loss decreased (0.885401 --> 0.886329).  Saving model ...\n",
      "Epoch 81: Train-Loss: 0.0010970572475343943, Val-Loss: 0.0021132829133421183, Val-AUC: 0.8863288927713474\n",
      "Epoch 82: Train-Loss: 0.001138146035373211, Val-Loss: 0.002263858215883374, Val-AUC: 0.8780301375846254\n",
      "Validation loss decreased (0.886329 --> 0.886438).  Saving model ...\n",
      "Epoch 83: Train-Loss: 0.0010991205926984549, Val-Loss: 0.0022853901609778404, Val-AUC: 0.8864380869185412\n",
      "Epoch 84: Train-Loss: 0.0011327324900776148, Val-Loss: 0.002156914444640279, Val-AUC: 0.8753548809783795\n",
      "Epoch 85: Train-Loss: 0.0011426822748035192, Val-Loss: 0.002246371703222394, Val-AUC: 0.8677658877484167\n",
      "Epoch 86: Train-Loss: 0.001110595534555614, Val-Loss: 0.0022405574563890696, Val-AUC: 0.8500218388294387\n",
      "Epoch 87: Train-Loss: 0.0010986371198669076, Val-Loss: 0.0021925964392721653, Val-AUC: 0.8799956322341123\n",
      "Epoch 88: Train-Loss: 0.0011383845703676343, Val-Loss: 0.0023328843526542187, Val-AUC: 0.8819611268835991\n",
      "Epoch 89: Train-Loss: 0.0011213069083169103, Val-Loss: 0.0023434110917150974, Val-AUC: 0.8773749727014633\n",
      "Epoch 90: Train-Loss: 0.0011559046106413007, Val-Loss: 0.0021625447552651167, Val-AUC: 0.8597401179296791\n",
      "Epoch 91: Train-Loss: 0.0011506048031151295, Val-Loss: 0.0022327627521008253, Val-AUC: 0.8572832496178204\n",
      "Epoch 92: Train-Loss: 0.0010795136913657188, Val-Loss: 0.0021438971161842346, Val-AUC: 0.848766106136711\n",
      "Epoch 93: Train-Loss: 0.001122905290685594, Val-Loss: 0.0021779495291411877, Val-AUC: 0.8617056125791657\n",
      "Epoch 94: Train-Loss: 0.0011559586273506284, Val-Loss: 0.00224294513463974, Val-AUC: 0.876665210744704\n",
      "Epoch 95: Train-Loss: 0.0011279350146651268, Val-Loss: 0.0021887158509343863, Val-AUC: 0.8522057217733129\n",
      "Epoch 96: Train-Loss: 0.0010987493442371488, Val-Loss: 0.002212587743997574, Val-AUC: 0.8820703210307927\n",
      "Epoch 97: Train-Loss: 0.0011544347507879138, Val-Loss: 0.002386109670624137, Val-AUC: 0.868038873116401\n",
      "Epoch 98: Train-Loss: 0.001058019115589559, Val-Loss: 0.0021446170285344124, Val-AUC: 0.8592487442673072\n",
      "Epoch 99: Train-Loss: 0.001126780640333891, Val-Loss: 0.0021308772265911102, Val-AUC: 0.8609958506224067\n",
      "Epoch 100: Train-Loss: 0.0010983053361997008, Val-Loss: 0.002190631115809083, Val-AUC: 0.8708779209434374\n",
      "Epoch 101: Train-Loss: 0.0011175319086760283, Val-Loss: 0.002155051566660404, Val-AUC: 0.878958287835772\n",
      "Epoch 102: Train-Loss: 0.0011058204108849168, Val-Loss: 0.0022307531908154488, Val-AUC: 0.8483839266215331\n",
      "Validation loss decreased (0.886438 --> 0.891243).  Saving model ...\n",
      "Epoch 103: Train-Loss: 0.001124013215303421, Val-Loss: 0.002150763990357518, Val-AUC: 0.8912426293950644\n",
      "Epoch 104: Train-Loss: 0.0011031447211280465, Val-Loss: 0.0022370154038071632, Val-AUC: 0.8671653199388514\n",
      "Epoch 105: Train-Loss: 0.0011354986345395446, Val-Loss: 0.0022540315985679626, Val-AUC: 0.8742083424328456\n",
      "Epoch 106: Train-Loss: 0.0010998675134032965, Val-Loss: 0.0020598627161234617, Val-AUC: 0.8658549901725268\n",
      "Epoch 107: Train-Loss: 0.0011058173840865493, Val-Loss: 0.002068485366180539, Val-AUC: 0.8801048263813058\n",
      "Epoch 108: Train-Loss: 0.001111072488129139, Val-Loss: 0.0023304992355406284, Val-AUC: 0.8542804105699935\n",
      "Epoch 109: Train-Loss: 0.0010921488283202052, Val-Loss: 0.0021818627137690783, Val-AUC: 0.8620331950207468\n",
      "Epoch 110: Train-Loss: 0.0010767843341454864, Val-Loss: 0.0023503380361944437, Val-AUC: 0.8774841668486568\n",
      "Epoch 111: Train-Loss: 0.0010808295337483287, Val-Loss: 0.0020811338908970356, Val-AUC: 0.864599257479799\n",
      "Epoch 112: Train-Loss: 0.001104963943362236, Val-Loss: 0.002178073860704899, Val-AUC: 0.8809783795588557\n",
      "Epoch 113: Train-Loss: 0.001093795639462769, Val-Loss: 0.0021997294388711452, Val-AUC: 0.8710963092378249\n",
      "Epoch 114: Train-Loss: 0.001119617954827845, Val-Loss: 0.0021206268575042486, Val-AUC: 0.8362633762830312\n",
      "Epoch 115: Train-Loss: 0.0011535121593624353, Val-Loss: 0.002141395816579461, Val-AUC: 0.8865472810657348\n",
      "Epoch 116: Train-Loss: 0.0010905034141615033, Val-Loss: 0.0021430363412946463, Val-AUC: 0.8280738152435029\n",
      "Epoch 117: Train-Loss: 0.0011215643025934696, Val-Loss: 0.002125589409843087, Val-AUC: 0.8609958506224067\n",
      "Epoch 118: Train-Loss: 0.0010987725108861923, Val-Loss: 0.00216175545938313, Val-AUC: 0.8742629395064425\n",
      "Epoch 119: Train-Loss: 0.0011051890905946493, Val-Loss: 0.0021631806157529354, Val-AUC: 0.860122297444857\n",
      "Epoch 120: Train-Loss: 0.0011408320860937238, Val-Loss: 0.0022749726194888353, Val-AUC: 0.8879668049792531\n",
      "Epoch 121: Train-Loss: 0.0010955363977700472, Val-Loss: 0.0021291819866746664, Val-AUC: 0.8408495304651671\n",
      "Epoch 122: Train-Loss: 0.0011331335408613086, Val-Loss: 0.0021546364296227694, Val-AUC: 0.874808910242411\n",
      "Epoch 123: Train-Loss: 0.0011198812862858176, Val-Loss: 0.0022031303960829973, Val-AUC: 0.8813059620004368\n",
      "Epoch 124: Train-Loss: 0.0010985183762386441, Val-Loss: 0.0021294276230037212, Val-AUC: 0.8617602096527626\n",
      "Epoch 125: Train-Loss: 0.0010788647923618555, Val-Loss: 0.002081101993098855, Val-AUC: 0.8743175365800393\n",
      "Epoch 126: Train-Loss: 0.001123162335716188, Val-Loss: 0.002121093450114131, Val-AUC: 0.8340248962655601\n",
      "Epoch 127: Train-Loss: 0.0011025882558897138, Val-Loss: 0.002119273878633976, Val-AUC: 0.8803778117492902\n",
      "Epoch 128: Train-Loss: 0.0010872059501707554, Val-Loss: 0.0022805931512266397, Val-AUC: 0.8848001747106355\n",
      "Epoch 129: Train-Loss: 0.0010793056571856141, Val-Loss: 0.0021637948229908943, Val-AUC: 0.7949333915702119\n",
      "Epoch 130: Train-Loss: 0.0010749492794275284, Val-Loss: 0.0022146590054035187, Val-AUC: 0.8891133435247871\n",
      "Epoch 131: Train-Loss: 0.0010807677172124386, Val-Loss: 0.002274753525853157, Val-AUC: 0.8832714566499236\n",
      "Epoch 132: Train-Loss: 0.0011140850838273764, Val-Loss: 0.0022454820573329926, Val-AUC: 0.8678204848220136\n",
      "Epoch 133: Train-Loss: 0.0011229030787944794, Val-Loss: 0.002102298429235816, Val-AUC: 0.8703319502074689\n",
      "Epoch 134: Train-Loss: 0.0010836776345968246, Val-Loss: 0.002091667614877224, Val-AUC: 0.884963965931426\n",
      "Epoch 135: Train-Loss: 0.0011092119384557009, Val-Loss: 0.0021565863862633705, Val-AUC: 0.871041712164228\n",
      "Epoch 136: Train-Loss: 0.001113510224968195, Val-Loss: 0.00214565871283412, Val-AUC: 0.8742629395064424\n",
      "Epoch 137: Train-Loss: 0.0011482798727229238, Val-Loss: 0.0024070541840046644, Val-AUC: 0.8688578292203538\n",
      "Epoch 138: Train-Loss: 0.0011392388259992003, Val-Loss: 0.002156444825232029, Val-AUC: 0.8608320594016161\n",
      "Epoch 139: Train-Loss: 0.0011300350306555629, Val-Loss: 0.002153958659619093, Val-AUC: 0.861268835990391\n",
      "Epoch 140: Train-Loss: 0.0011463568080216646, Val-Loss: 0.0021476796828210354, Val-AUC: 0.8793404673509501\n",
      "Epoch 141: Train-Loss: 0.001115107093937695, Val-Loss: 0.0021084502805024385, Val-AUC: 0.8827254859139549\n",
      "Epoch 142: Train-Loss: 0.0011068856110796332, Val-Loss: 0.0023313823621720076, Val-AUC: 0.8544987988643808\n",
      "Epoch 143: Train-Loss: 0.0011559384874999523, Val-Loss: 0.002324567409232259, Val-AUC: 0.871806071194584\n",
      "Epoch 144: Train-Loss: 0.0010966965928673744, Val-Loss: 0.0021097881253808737, Val-AUC: 0.8661279755405109\n",
      "Epoch 145: Train-Loss: 0.0011115734232589602, Val-Loss: 0.002187145408242941, Val-AUC: 0.8749727014632016\n",
      "Epoch 146: Train-Loss: 0.0010921830544248223, Val-Loss: 0.0021135651040822268, Val-AUC: 0.8505678095654072\n",
      "Epoch 147: Train-Loss: 0.0011115568922832608, Val-Loss: 0.0022703276481479406, Val-AUC: 0.8801048263813059\n",
      "Epoch 148: Train-Loss: 0.0011017895303666592, Val-Loss: 0.002193551743403077, Val-AUC: 0.8723520419305526\n",
      "Epoch 149: Train-Loss: 0.0010583278490230441, Val-Loss: 0.0021530676167458296, Val-AUC: 0.8760100458615419\n",
      "Epoch 150: Train-Loss: 0.0010954411700367928, Val-Loss: 0.002289456780999899, Val-AUC: 0.8710963092378249\n",
      "Epoch 151: Train-Loss: 0.0010941745713353157, Val-Loss: 0.0021797611843794584, Val-AUC: 0.8701135619130815\n",
      "Epoch 152: Train-Loss: 0.0010985404951497912, Val-Loss: 0.002161978743970394, Val-AUC: 0.8756278663463638\n",
      "Epoch 153: Train-Loss: 0.00108741270378232, Val-Loss: 0.002161639742553234, Val-AUC: 0.8552085608211399\n",
      "Epoch 154: Train-Loss: 0.0010800960008054972, Val-Loss: 0.0022424240596592426, Val-AUC: 0.8750818956103953\n",
      "Epoch 155: Train-Loss: 0.00108869350515306, Val-Loss: 0.002253785729408264, Val-AUC: 0.8707141297226468\n",
      "Epoch 156: Train-Loss: 0.0010854515712708235, Val-Loss: 0.002265013288706541, Val-AUC: 0.8740445512120552\n",
      "Epoch 157: Train-Loss: 0.0010961131192743778, Val-Loss: 0.0022801412269473076, Val-AUC: 0.8773203756278662\n",
      "Epoch 158: Train-Loss: 0.0010963502572849393, Val-Loss: 0.0021921973675489426, Val-AUC: 0.8655274077309456\n",
      "Epoch 159: Train-Loss: 0.0011155321262776852, Val-Loss: 0.0021405781153589487, Val-AUC: 0.865363616510155\n",
      "Epoch 160: Train-Loss: 0.001084420015104115, Val-Loss: 0.0021798131056129932, Val-AUC: 0.8567918759554489\n",
      "Epoch 161: Train-Loss: 0.0010809723753482103, Val-Loss: 0.0022323420271277428, Val-AUC: 0.867219917012448\n",
      "Epoch 162: Train-Loss: 0.0010989035945385695, Val-Loss: 0.002234578365460038, Val-AUC: 0.8689670233675475\n",
      "Epoch 163: Train-Loss: 0.001070433179847896, Val-Loss: 0.00209713913500309, Val-AUC: 0.8736623716968771\n",
      "Epoch 164: Train-Loss: 0.0010751193622127175, Val-Loss: 0.0021812082268297672, Val-AUC: 0.8661279755405109\n",
      "Epoch 165: Train-Loss: 0.001091308775357902, Val-Loss: 0.0021778938826173544, Val-AUC: 0.8573924437650142\n",
      "Epoch 166: Train-Loss: 0.0010727007174864411, Val-Loss: 0.002083562547340989, Val-AUC: 0.8588665647521293\n",
      "Epoch 167: Train-Loss: 0.0011149890488013625, Val-Loss: 0.002185962162911892, Val-AUC: 0.8801048263813059\n",
      "Epoch 168: Train-Loss: 0.001126595539972186, Val-Loss: 0.0020907616708427668, Val-AUC: 0.8567372788818519\n",
      "Epoch 169: Train-Loss: 0.0010794918052852154, Val-Loss: 0.002165223006159067, Val-AUC: 0.8527516925092815\n",
      "Epoch 170: Train-Loss: 0.0010687669273465872, Val-Loss: 0.002124016871675849, Val-AUC: 0.8685848438523696\n",
      "Epoch 171: Train-Loss: 0.0011469315504655242, Val-Loss: 0.00231393170543015, Val-AUC: 0.885728324961782\n",
      "Epoch 172: Train-Loss: 0.0010926824761554599, Val-Loss: 0.002151983557268977, Val-AUC: 0.8778117492902381\n",
      "Epoch 173: Train-Loss: 0.001118327141739428, Val-Loss: 0.002170218387618661, Val-AUC: 0.8708779209434374\n",
      "Epoch 174: Train-Loss: 0.001091170939616859, Val-Loss: 0.0021483313757926226, Val-AUC: 0.8629613452718934\n",
      "Epoch 175: Train-Loss: 0.001118395826779306, Val-Loss: 0.002253737999126315, Val-AUC: 0.8785215112469973\n",
      "Epoch 176: Train-Loss: 0.0010745312320068479, Val-Loss: 0.002161971526220441, Val-AUC: 0.8663463638348985\n",
      "Epoch 177: Train-Loss: 0.0010881207417696714, Val-Loss: 0.002113394672051072, Val-AUC: 0.8454356846473028\n",
      "Epoch 178: Train-Loss: 0.0011118848342448473, Val-Loss: 0.002218428300693631, Val-AUC: 0.8771565844070758\n",
      "Epoch 179: Train-Loss: 0.0010575319174677134, Val-Loss: 0.0021973242983222008, Val-AUC: 0.8767744048918978\n",
      "Epoch 180: Train-Loss: 0.0010993645992130041, Val-Loss: 0.002175317145884037, Val-AUC: 0.8755186721991701\n",
      "Epoch 181: Train-Loss: 0.0010934536112472415, Val-Loss: 0.0021661005448549986, Val-AUC: 0.8860013103297663\n",
      "Epoch 182: Train-Loss: 0.0010941305663436651, Val-Loss: 0.0022479575127363205, Val-AUC: 0.8840358156802794\n",
      "Epoch 183: Train-Loss: 0.0010974849574267864, Val-Loss: 0.002295870566740632, Val-AUC: 0.8802686176020965\n",
      "Epoch 184: Train-Loss: 0.0010806324426084757, Val-Loss: 0.0023310540709644556, Val-AUC: 0.880487005896484\n",
      "Epoch 185: Train-Loss: 0.0010624596616253257, Val-Loss: 0.002135745482519269, Val-AUC: 0.8792312732037563\n",
      "Epoch 186: Train-Loss: 0.0010756488190963864, Val-Loss: 0.002297199098393321, Val-AUC: 0.8891679405983839\n",
      "Epoch 187: Train-Loss: 0.001121952896937728, Val-Loss: 0.002231261460110545, Val-AUC: 0.8591395501201136\n",
      "Epoch 188: Train-Loss: 0.001083678798750043, Val-Loss: 0.0021723455283790827, Val-AUC: 0.8796134527189343\n",
      "Epoch 189: Train-Loss: 0.0010893564904108644, Val-Loss: 0.0021346863359212875, Val-AUC: 0.8721336536361652\n",
      "Epoch 190: Train-Loss: 0.0010465398663654923, Val-Loss: 0.00214792019687593, Val-AUC: 0.8665647521292859\n",
      "Epoch 191: Train-Loss: 0.0011203381000086665, Val-Loss: 0.0021294825710356236, Val-AUC: 0.883053068355536\n",
      "Epoch 192: Train-Loss: 0.001059128437191248, Val-Loss: 0.002161882584914565, Val-AUC: 0.8718606682681809\n",
      "Epoch 193: Train-Loss: 0.0011136375833302736, Val-Loss: 0.0021772137843072414, Val-AUC: 0.8599585062240664\n",
      "Epoch 194: Train-Loss: 0.0010954116005450487, Val-Loss: 0.002342344494536519, Val-AUC: 0.8804324088228872\n",
      "Epoch 195: Train-Loss: 0.0010652997298166156, Val-Loss: 0.0023230952210724354, Val-AUC: 0.8673837082332387\n",
      "Epoch 196: Train-Loss: 0.0010671396739780903, Val-Loss: 0.002075985074043274, Val-AUC: 0.877047390259882\n",
      "Epoch 197: Train-Loss: 0.0011126992758363485, Val-Loss: 0.002150777028873563, Val-AUC: 0.8737169687704739\n",
      "Epoch 198: Train-Loss: 0.0011578128905966878, Val-Loss: 0.0021490647923201323, Val-AUC: 0.8502402271238262\n",
      "Epoch 199: Train-Loss: 0.0010938140330836177, Val-Loss: 0.002235252410173416, Val-AUC: 0.8391024241100677\n",
      "Epoch 200: Train-Loss: 0.0010818673763424158, Val-Loss: 0.0020934795029461384, Val-AUC: 0.8683664555579821\n",
      "Epoch 201: Train-Loss: 0.0010628545423969626, Val-Loss: 0.0021401308476924896, Val-AUC: 0.8866564752129286\n",
      "Epoch 202: Train-Loss: 0.0010910091223195195, Val-Loss: 0.002118033589795232, Val-AUC: 0.8762830312295261\n",
      "Epoch 203: Train-Loss: 0.001087667653337121, Val-Loss: 0.002207869663834572, Val-AUC: 0.8744267307272329\n",
      "Epoch 204: Train-Loss: 0.0010785802733153105, Val-Loss: 0.002141506178304553, Val-AUC: 0.8660187813933172\n",
      "Epoch 205: Train-Loss: 0.0011215725680813193, Val-Loss: 0.002180723939090967, Val-AUC: 0.8663463638348984\n",
      "Epoch 206: Train-Loss: 0.0011003179242834449, Val-Loss: 0.002251584781333804, Val-AUC: 0.8554815461891243\n",
      "Epoch 207: Train-Loss: 0.0010809642262756824, Val-Loss: 0.0022760843858122826, Val-AUC: 0.8562459052194803\n",
      "Epoch 208: Train-Loss: 0.001079523703083396, Val-Loss: 0.0021998391021043062, Val-AUC: 0.8839266215330858\n",
      "Epoch 209: Train-Loss: 0.0010998278157785535, Val-Loss: 0.002259655389934778, Val-AUC: 0.8570102642498363\n",
      "Epoch 210: Train-Loss: 0.0010624293936416507, Val-Loss: 0.002131409477442503, Val-AUC: 0.8731164009609085\n",
      "Epoch 211: Train-Loss: 0.0010953909950330853, Val-Loss: 0.002204964403063059, Val-AUC: 0.8607774623280192\n",
      "Epoch 212: Train-Loss: 0.001065105083398521, Val-Loss: 0.002134226728230715, Val-AUC: 0.8706049355754532\n",
      "Epoch 213: Train-Loss: 0.0010640304535627365, Val-Loss: 0.0021140030585229397, Val-AUC: 0.865363616510155\n",
      "Epoch 214: Train-Loss: 0.0010912385769188404, Val-Loss: 0.0021937647834420204, Val-AUC: 0.8830530683555361\n",
      "Epoch 215: Train-Loss: 0.0009757253574207425, Val-Loss: 0.0022400913294404745, Val-AUC: 0.8720790565625682\n",
      "Epoch 216: Train-Loss: 0.001128248986788094, Val-Loss: 0.002128796186298132, Val-AUC: 0.8683118584843852\n",
      "Epoch 217: Train-Loss: 0.0010653079953044653, Val-Loss: 0.002202284289523959, Val-AUC: 0.8446713256169469\n",
      "Epoch 218: Train-Loss: 0.001075556268915534, Val-Loss: 0.002218205714598298, Val-AUC: 0.8877484166848657\n",
      "Epoch 219: Train-Loss: 0.0010813568951562047, Val-Loss: 0.002415253547951579, Val-AUC: 0.8628521511246997\n",
      "Epoch 220: Train-Loss: 0.0010597632499411702, Val-Loss: 0.0021843293216079473, Val-AUC: 0.8660733784669142\n",
      "Epoch 221: Train-Loss: 0.0010914095910266042, Val-Loss: 0.0021595756988972425, Val-AUC: 0.8634527189342651\n",
      "Epoch 222: Train-Loss: 0.001097090425901115, Val-Loss: 0.0021272776648402214, Val-AUC: 0.8801594234549027\n",
      "Epoch 223: Train-Loss: 0.001078413799405098, Val-Loss: 0.002233728300780058, Val-AUC: 0.8618148067263595\n",
      "Epoch 224: Train-Loss: 0.0010744408937171102, Val-Loss: 0.0021967587526887655, Val-AUC: 0.8754094780519764\n",
      "Epoch 225: Train-Loss: 0.001095722196623683, Val-Loss: 0.002144034020602703, Val-AUC: 0.8769381961126883\n",
      "Epoch 226: Train-Loss: 0.0010513024171814322, Val-Loss: 0.0021575158461928368, Val-AUC: 0.8554269491155274\n",
      "Epoch 227: Train-Loss: 0.001077344873920083, Val-Loss: 0.002170141786336899, Val-AUC: 0.8658549901725268\n",
      "Epoch 228: Train-Loss: 0.0010911201825365424, Val-Loss: 0.0022417278960347176, Val-AUC: 0.8876938196112688\n",
      "Epoch 229: Train-Loss: 0.0011194099206477404, Val-Loss: 0.0021430128253996372, Val-AUC: 0.881578947368421\n",
      "Epoch 230: Train-Loss: 0.0010527123231440783, Val-Loss: 0.002247778931632638, Val-AUC: 0.8730618038873116\n",
      "Epoch 231: Train-Loss: 0.0010653146309778094, Val-Loss: 0.0021209963597357273, Val-AUC: 0.8487115090631141\n",
      "Epoch 232: Train-Loss: 0.0011078258976340294, Val-Loss: 0.0022065271623432636, Val-AUC: 0.8660733784669141\n",
      "Epoch 233: Train-Loss: 0.001072539365850389, Val-Loss: 0.0022423570044338703, Val-AUC: 0.8630705394190871\n",
      "Epoch 234: Train-Loss: 0.0011194690596312284, Val-Loss: 0.002212516264989972, Val-AUC: 0.8697859794715003\n",
      "Epoch 235: Train-Loss: 0.0010878251632675529, Val-Loss: 0.0021925829350948334, Val-AUC: 0.8666739462764795\n",
      "Epoch 236: Train-Loss: 0.001118868705816567, Val-Loss: 0.002176632871851325, Val-AUC: 0.8772111814806727\n",
      "Epoch 237: Train-Loss: 0.001068033860065043, Val-Loss: 0.0021461460273712873, Val-AUC: 0.8765560165975104\n",
      "Epoch 238: Train-Loss: 0.0010927766561508179, Val-Loss: 0.0022576767951250076, Val-AUC: 0.8821795151779864\n",
      "Epoch 239: Train-Loss: 0.0011026713764294982, Val-Loss: 0.0022934158332645893, Val-AUC: 0.871423891679406\n",
      "Epoch 240: Train-Loss: 0.00109344522934407, Val-Loss: 0.0021765371784567833, Val-AUC: 0.8615418213583752\n",
      "Epoch 241: Train-Loss: 0.0011249628150835633, Val-Loss: 0.0022362377494573593, Val-AUC: 0.8774841668486569\n",
      "Epoch 242: Train-Loss: 0.0011050013126805425, Val-Loss: 0.0023508237209171057, Val-AUC: 0.8771565844070757\n",
      "Epoch 243: Train-Loss: 0.0010598857188597322, Val-Loss: 0.002170929918065667, Val-AUC: 0.8632889277134744\n",
      "Epoch 244: Train-Loss: 0.001094076782464981, Val-Loss: 0.0021754892077296972, Val-AUC: 0.865363616510155\n",
      "Epoch 245: Train-Loss: 0.0011151252547279, Val-Loss: 0.0022651932667940855, Val-AUC: 0.8736623716968771\n",
      "Epoch 246: Train-Loss: 0.0010784112382680178, Val-Loss: 0.0021930134389549494, Val-AUC: 0.878958287835772\n",
      "Epoch 247: Train-Loss: 0.0010964891407638788, Val-Loss: 0.0022941746283322573, Val-AUC: 0.87065953264905\n",
      "Epoch 248: Train-Loss: 0.0011188656790181994, Val-Loss: 0.002272964920848608, Val-AUC: 0.879285870277353\n",
      "Epoch 249: Train-Loss: 0.0010862044291570783, Val-Loss: 0.0021682833321392536, Val-AUC: 0.8603952828128412\n",
      "Epoch 250: Train-Loss: 0.001100732944905758, Val-Loss: 0.002217070199549198, Val-AUC: 0.8817973356628084\n",
      "Epoch 251: Train-Loss: 0.0010765006300061941, Val-Loss: 0.002187174977734685, Val-AUC: 0.8675474994540293\n",
      "Epoch 252: Train-Loss: 0.001072819228284061, Val-Loss: 0.002234797924757004, Val-AUC: 0.8569010701026425\n",
      "Epoch 253: Train-Loss: 0.0010853111743927002, Val-Loss: 0.0022080177441239357, Val-AUC: 0.8789036907621751\n",
      "Training Finished\n",
      "Set threshold to 0.018666400715257183\n",
      "Using Threshold == 0.018666400715257183\n",
      "Train Loss: 0.0010111478623002768, AUC: 0.9050684250113628, F1: 0.21814543800686642, Precision: 0.12255825847387314, Recall: 0.9912663698196411\n",
      "Test Loss: 0.0017702626064419746, AUC: 0.8739023760330579, F1: 0.10654057516994304, Precision: 0.05626768618822098, Recall: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0017702626,\n",
       " 0.8739023760330579,\n",
       " 0.10654057516994304,\n",
       " 0.056267686,\n",
       " 1.0,\n",
       " 0.0010111479,\n",
       " 0.9050684250113628,\n",
       " 0.21814543800686642,\n",
       " 0.12255826,\n",
       " 0.99126637)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tcnAnomalyDetector.create_model()\n",
    "tcnAnomalyDetector.create_datasets()\n",
    "    \n",
    "tcnAnomalyDetector.train(use_wandb=False, save_path=\"./\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
